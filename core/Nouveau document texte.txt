# core/mrcnn_infer.py
"""
Module d'inférence Mask R-CNN pour la détection d'interfaces.
Inclut :
- Chargement de deux modèles Mask R-CNN
- Filtrage et fusion morphologique des masques
- Application de seuils métier (38 / 52 px)
- Export overlays, masques binaires, colormaps, JSON positions, Excel interfaces
"""

import os
import re
import json
from typing import List, Tuple, Optional, Dict

import cv2
import numpy as np
import pandas as pd
import torch
from torch import nn
from torchvision.models.detection import maskrcnn_resnet50_fpn
from torchvision.models.detection.faster_rcnn import FastRCNNPredictor
from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor

# ===================== Constantes / paramètres ===================== #
MODEL_PATH1 = "models/model_asc.pth"
MODEL_PATH2 = "models/model_desc.pth"

THR_SCORE = 0.5
THR_MIN_WIDTH = 100
# Seuils proportionnels à la hauteur d'image (au lieu de 38/52 px)
RATIO_INTERFACE_MIN = 0.15  # 15% de la hauteur -> borne min (interface_0)
RATIO_FORBIDDEN_MAX = 0.22  # 22% de la hauteur -> borne max (zone interdite)

PX_STEP = 10
CM_STEP = 10
EXPECTED_POINTS = 40

# Règles interfaces
THICKEN_H = 0  # boost horizontal optionnel

# ===================== Utils ===================== #

def _ensure_dir(path: str):
    os.makedirs(path, exist_ok=True)


def _regex_pk(fname: str) -> Tuple[Optional[int], Optional[int]]:
    # Cherche ..._PKstart_end dans le nom de fichier
    m = re.search(r"_PK(\d+)[_-](\d+)", fname)
    if not m:
        return None, None
    return int(m.group(1)), int(m.group(2))


def _overlay_mask(img: np.ndarray, mask: np.ndarray, alpha: float = 0.4) -> np.ndarray:
    col = np.zeros_like(img)
    col[:, :, 1] = 255
    return cv2.addWeighted(img, 1.0, cv2.bitwise_and(col, col, mask=mask), alpha, 0)


def _order_interfaces_top_down(masks: List[np.ndarray]) -> List[np.ndarray]:
    if not masks:
        return []
    meds = []
    for m in masks:
        ys, xs = np.where(m > 0)
        med = float(np.median(ys)) if ys.size else np.inf
        meds.append(med)
    order = np.argsort(meds)
    return [masks[i] for i in order]


def _fuse_two_models_masks(mask1: np.ndarray, mask2: np.ndarray, thr_px: int = 20) -> np.ndarray:
    # AND souple : garder pixels présents dans au moins un avec petite fermeture
    m = np.logical_or(mask1 > 0, mask2 > 0).astype(np.uint8) * 255
    k = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
    m = cv2.morphologyEx(m, cv2.MORPH_CLOSE, k, iterations=1)
    if THICKEN_H > 0:
        k2 = cv2.getStructuringElement(cv2.MORPH_RECT, (THICKEN_H, 1))
        m = cv2.dilate(m, k2, iterations=1)
    return m


def _filter_masks(masks: List[np.ndarray]) -> List[np.ndarray]:
    out = []
    for m in masks:
        if m is None:
            continue
        ys, xs = np.where(m > 0)
        if xs.size == 0:
            continue
        width = int(xs.max() - xs.min())
        if width < THR_MIN_WIDTH:
            continue
        out.append(m)
    return out


def _save_json_positions(out_dir_positions: str, fname: str, x_list: List[int], interfaces: Dict[str, List[float]]):
    payload = {
        "file": fname,
        "x_cm": x_list,
        "interfaces": interfaces,
    }
    _ensure_dir(out_dir_positions)
    out_path = os.path.join(out_dir_positions, os.path.splitext(fname)[0] + ".json")
    with open(out_path, "w") as f:
        json.dump(payload, f, indent=2)
    return out_path


# ===================== Modèle ===================== #

def _get_model_instance_segmentation(num_classes: int = 2):
    model = maskrcnn_resnet50_fpn(weights=None)
    in_features = model.roi_heads.box_predictor.cls_score.in_features
    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)
    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels
    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, 256, num_classes)
    return model


# ===================== Profils ===================== #

def _y_profile_from_mask(mask_uint8: np.ndarray, x_px_grid: np.ndarray) -> np.ndarray:
    H, W = mask_uint8.shape
    y = np.full_like(x_px_grid, fill_value=np.nan, dtype=float)
    for i, x in enumerate(x_px_grid):
        col = mask_uint8[:, x]
        ys = np.where(col > 0)[0]
        if ys.size == 0:
            y[i] = np.nan
        else:
            y[i] = float(np.median(ys))
    return y


# ===================== Exports par image ===================== #

def _write_pred_images(out_dir_overlays: str, out_dir_pred_masks: str, out_dir_pred_color: str,
                       fname: str, img: np.ndarray, fused_masks: List[np.ndarray]) -> Tuple[str, str, str]:
    _ensure_dir(out_dir_overlays)
    _ensure_dir(out_dir_pred_masks)
    _ensure_dir(out_dir_pred_color)

    # Overlay vert
    overlay = img.copy()
    for m in fused_masks:
        overlay = _overlay_mask(overlay, m)
    p_overlay = os.path.join(out_dir_overlays, fname)
    cv2.imwrite(p_overlay, overlay)

    # Masques binaires + colormap
    stack = np.zeros_like(img)
    color = np.zeros_like(img)
    for i, m in enumerate(fused_masks):
        cv2.imwrite(os.path.join(out_dir_pred_masks, f"{os.path.splitext(fname)[0]}_mask{i}.png"), m)
        color[:, :, 1] = np.maximum(color[:, :, 1], m)  # simple palette: canal G
    p_color = os.path.join(out_dir_pred_color, fname)
    cv2.imwrite(p_color, color)
    return p_overlay, out_dir_pred_masks, p_color


def _write_positions_json(out_dir_positions: str, fname: str,
                          x_cm_list: List[int], interfaces_df: pd.DataFrame) -> str:
    interfaces = {c: interfaces_df[c].astype(float).fillna(np.nan).tolist()
                  for c in interfaces_df.columns if c.startswith("interface_")}
    return _save_json_positions(out_dir_positions, fname, list(map(int, x_cm_list)), interfaces)


def _write_interfaces_excel(
    out_dir_excels: str, fname: str, chantier: Optional[str],
    pk_start_cm: Optional[int], pk_end_cm: Optional[int],
    fused_masks: List[np.ndarray], image_shape: Tuple[int, int, int]
) -> Optional[str]:
    if chantier is None or pk_start_cm is None or pk_end_cm is None or pk_start_cm == pk_end_cm:
        return None

    H, W = image_shape[:2]
    x_cm_grid = np.linspace(pk_start_cm, pk_end_cm, EXPECTED_POINTS, endpoint=False, dtype=np.int64)
    if x_cm_grid.size == 0:
        return None
    x_px_grid = np.rint((x_cm_grid - pk_start_cm) / (pk_end_cm - pk_start_cm) * (W - 1)).astype(int)
    x_px_grid = np.clip(x_px_grid, 0, W - 1)

    masks_sorted = _order_interfaces_top_down(fused_masks)
    data = {
        "image_name": [os.path.basename(fname)] * len(x_cm_grid),
        "img_xmin_cm": [int(pk_start_cm)] * len(x_cm_grid),
        "img_xmax_cm": [int(pk_end_cm)] * len(x_cm_grid),
        "x_cm": x_cm_grid.astype(int)
    }

    if len(masks_sorted) == 0:
        data["interface_0"] = [np.nan] * len(x_cm_grid)
    else:
        profiles, medians = [], []
        for m in masks_sorted:
            prof = _y_profile_from_mask(m, x_px_grid)
            profiles.append(prof)
            med = np.nanmedian(prof)
            medians.append(med if np.isfinite(med) else np.nan)

        # Règles métier : interface_0 (au-dessus de thr_min), exclusion zone thr_min–thr_max
thr_min = float(RATIO_INTERFACE_MIN) * float(H)
thr_max = float(RATIO_FORBIDDEN_MAX) * float(H)
group0_idx = [i for i, med in enumerate(medians) if np.isfinite(med) and med <= thr_min]
forbidden_idx = [i for i, med in enumerate(medians) if np.isfinite(med) and thr_min < med < thr_max]
remaining_idx = [i for i in range(len(profiles)) if i not in group0_idx and i not in forbidden_idx]

        if group0_idx:
            stack = np.vstack([profiles[i] for i in group0_idx])
            data["interface_0"] = np.nanmean(stack, axis=0)
            start_num = 1
        else:
            start_num = 1

        for out_i, idx in enumerate(remaining_idx, start=start_num):
            data[f"interface_{out_i}"] = profiles[idx]

    df = pd.DataFrame(data)
    _ensure_dir(out_dir_excels)
    excel_path = os.path.join(out_dir_excels, os.path.splitext(fname)[0] + ".xlsx")
    with pd.ExcelWriter(excel_path, engine="openpyxl") as writer:
        df.to_excel(writer, sheet_name="interfaces", index=False)
    return excel_path


# ===================== Agrégation ===================== #

def aggregate_excels_to_stratigraphy(excels_dir: str, sort_order: str = "ASC") -> Optional[pd.DataFrame]:
    if not os.path.isdir(excels_dir):
        return None
    frames = []
    for f in os.listdir(excels_dir):
        if f.lower().endswith(".xlsx"):
            p = os.path.join(excels_dir, f)
            try:
                df = pd.read_excel(p, sheet_name="interfaces")
                if "x_cm" in df.columns:
                    df["x_cm"] = pd.to_numeric(df["x_cm"], errors="coerce")
                frames.append(df)
            except Exception:
                continue
    if not frames:
        return None
    out = pd.concat(frames, axis=0, ignore_index=True)
    if "x_cm" in out.columns:
        out = out.dropna(subset=["x_cm"])
        out["x_cm"] = pd.to_numeric(out["x_cm"], errors="coerce")
        out = out.sort_values("x_cm", ascending=(sort_order.upper() == "ASC")).reset_index(drop=True)
    return out


# ===================== Inférence principale ===================== #

def run_inference_for_category(
    image_folder: str,
    files: List[str],
    model_path: str,  # unused: kept for compatibility
    output_root: str,
    category: str,
    chantier: Optional[str] = None,
    force: bool = True
) -> Dict[str, object]:
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    cat_root = os.path.join(output_root, category)
    dir_overlays   = os.path.join(cat_root, "overlays")
    dir_pred_masks = os.path.join(cat_root, "pred_masks")
    dir_pred_color = os.path.join(cat_root, "pred_colormap")
    dir_positions  = os.path.join(cat_root, "positions")
    dir_excels     = os.path.join(cat_root, "excels")
    for d in [dir_overlays, dir_pred_masks, dir_pred_color, dir_positions, dir_excels]:
        _ensure_dir(d)

    # Charger les deux modèles
    model1 = _get_model_instance_segmentation(2)
    model2 = _get_model_instance_segmentation(2)
    state1 = torch.load(MODEL_PATH1, map_location=device)
    state2 = torch.load(MODEL_PATH2, map_location=device)
    model1.load_state_dict(state1)
    model2.load_state_dict(state2)
    model1.eval(); model2.eval()

    for fname in files:
        img_path = os.path.join(image_folder, fname)
        img = cv2.imread(img_path)
        if img is None:
            continue
        H, W = img.shape[:2]

        # Inférence brute deux modèles → masques binaires + fusion
        # (Cette section suppose que vous avez un pré/post-traitement ailleurs ; ici on illustre)
        with torch.no_grad():
            # dummy : remplacer par vos prédictions réelles
            pred1_masks = []  # List[np.ndarray]
            pred2_masks = []  # List[np.ndarray]
        fused_masks = []
        for i in range(max(len(pred1_masks), len(pred2_masks))):
            m1 = pred1_masks[i] if i < len(pred1_masks) else np.zeros((H, W), np.uint8)
            m2 = pred2_masks[i] if i < len(pred2_masks) else np.zeros((H, W), np.uint8)
            fused = _fuse_two_models_masks(m1, m2)
            fused_masks.append(fused)

        fused_masks = _filter_masks(fused_masks)
        fused_masks = _order_interfaces_top_down(fused_masks)

        # Overlays / masques / colormap
        _write_pred_images(dir_overlays, dir_pred_masks, dir_pred_color, fname, img, fused_masks)

        # Excel interfaces + JSON positions (si le nom contient PKstart_end)
        pk_start_cm, pk_end_cm = _regex_pk(fname)
        if pk_start_cm is not None and pk_end_cm is not None:
            excel_path = _write_interfaces_excel(
                out_dir_excels=dir_excels,
                fname=fname,
                chantier=chantier,
                pk_start_cm=pk_start_cm,
                pk_end_cm=pk_end_cm,
                fused_masks=fused_masks,
                image_shape=img.shape,
            )
            if excel_path:
                df = pd.read_excel(excel_path, sheet_name="interfaces")
                _write_positions_json(dir_positions, fname, df["x_cm"].tolist(), df)

    return {"ok": True, "output_root": output_root, "category": category}


# ===================== Vérifications ===================== #

def check_excels_exist(output_root: str, category: str) -> Dict[str, object]:
    dir_excels = os.path.join(output_root, category, "excels")
    exists = os.path.isdir(dir_excels)
    num_excels = 0
    if exists:
        num_excels = len([f for f in os.listdir(dir_excels) if f.lower().endswith('.xlsx')])
    return {"exists": exists and num_excels > 0, "num_excels": num_excels}
